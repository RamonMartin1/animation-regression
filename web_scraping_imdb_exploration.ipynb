{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project 2 to-dos:**\n",
    "* Write functions to pull title urls - **DONE**\n",
    "* Test functions on American/Japanese animated movie search (does it pull all the necessary movie imdb URLs)? - **DONE**\n",
    "* Read existing literature on box office revenue drivers - **DONE**\n",
    "* Create a list of necessary features\n",
    "* Create functions to scrape all the necessary data from each URL\n",
    "* Put all data into dataframe\n",
    "* Put functions into .py files\n",
    "* Read through linear regression notebooks\n",
    "* Train models\n",
    "* Cross-validate models \n",
    "* Test models\n",
    "* Explain/visualize results\n",
    "* Create PPT\n",
    "    * In appendix, note that I wasn't able to parse the exact release dates for Japanese movies (sometimes, the release date for a Japanese movie was the American release date, which tends to come after the Japanese release date by a year or two). This was because of the difficulty of parsing the Japanese release date (had to be parsed from a separate 'release date' URL/lack of time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project 2 Steps:**    \n",
    "1. Literature review\n",
    "2. Web scraping \n",
    "3. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project 2 Questions:**\n",
    "1. What to do about animated films made in both Japan/US? Just take them out of the dataset? Or put them in both the Japan/US regression? \n",
    "    * Take them out of the dataset to isolate the differences between Japanese and American animated films"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List of features:**\n",
    "* Title - **DONE**\n",
    "* Runtime - **DONE**\n",
    "* Budget - **DONE**\n",
    "* MPAA rating (e.g. G, PG, PG-13, R) - **DONE**\n",
    "* Release date - **DONE**\n",
    "    * Christmas/New Year release (December and first week of January)\n",
    "    * Summer release (June, July, August) \n",
    "    * \\# of years since release\n",
    "    * Differentiate in my larger function call between US and Japanese release date depending on country of the film\n",
    "* Genres - **DONE**\n",
    "* IMDb user rating (a weighted average score of user ratings; the weights are not disclosed) - **DONE**\n",
    "* \\# of IMDb user ratings - **DONE**\n",
    "* \\# of Oscar wins - **DONE**\n",
    "* \\# of total awards (since there are a lot of animation specific awards) - **DONE**\n",
    "* \\# of Oscar nominations - **LEAVE OUT FOR NOW**\n",
    "* \\# of total nominations - **LEAVE OUT FOR NOW**\n",
    "* Country - **DONE**\n",
    "* Metascore (a weighted average score of critic ratings; the weights are not disclosed)\n",
    "* What are the American animation/Japanese animation equivalent of Oscars?\n",
    "    * Annie Awards \n",
    "    * Japan Academy Awards\n",
    "* Sequel - **NOT AVAILABLE ON imdb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import dateutil.parser\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline\n",
    "sns.set(color_codes=True)\n",
    "plt.style.use('seaborn-colorblind')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.precision', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search: https://www.imdb.com/search/title/  \n",
    "Title type: Feature film  \n",
    "Release date: up to July 1, 2020\n",
    "Genres: Animation  \n",
    "Countries: Japan; United States (the countries need to be searched separately)  \n",
    "Display options: Detailed, 100 per page    \n",
    "Adult titles: Exclude  \n",
    "Sorted by: Release date descending  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search: https://pro.imdb.com/find?q=&showRVCWidget=true&ref_=hm_nv_search#keyspace=TITLE&sort=ranking  \n",
    "Type: Movie  \n",
    "Status: Released  \n",
    "Country: United States, Japan  \n",
    "**Note to self:** I can use beautifulsoup to find the individual links for each movie (from a search page) and then do a request for each of those individual links  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "japan_base_url = 'https://www.imdb.com/search/title/?title_type=feature&release_date=,' \\\n",
    "    '2020-07-01&genres=animation&countries=jp&sort=release_date,desc&count=' \\\n",
    "    '100&view=simple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.imdb.com/search/title/?title_type=feature&release_date=,2020-07-01&genres=animation&countries=jp&sort=release_date,desc&count=100&view=simple'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "japan_base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_base_url = 'https://www.imdb.com/search/title/?title_type=feature&release_date=,' \\\n",
    "                    '2020-07-01&genres=animation&countries=us&sort=release_date,desc&count=' \\\n",
    "                    '100&view=simple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "japan_next_url = 'https://www.imdb.com/search/title/?title_type=feature&release_date=,' \\\n",
    "    '2020-07-01&genres=animation&countries=jp&view=simple&sort=release_date,desc&count=' \\\n",
    "    '100&start=101&ref_=adv_nxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_next_url = 'https://www.imdb.com/search/title/?title_type=feature&release_date=,' \\\n",
    "                    '2020-07-01&genres=animation&countries=us&view=simple&sort=release_date,' \\\n",
    "                    'desc&count=100&start=101&ref_=adv_nxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_urls(base_url, next_url):\n",
    "    search_urls = [base_url, next_url]\n",
    "    num_titles = get_num_titles(base_url)\n",
    "\n",
    "    for i in range(num_titles//100-1):\n",
    "        search_urls.append(\n",
    "            next_url.replace('101', str(201+100*i)))\n",
    "    return search_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_titles(base_url):\n",
    "    soup = create_soup(base_url)\n",
    "    mini_header = soup.find('div', class_='desc').findNext().text.split()\n",
    "    num_titles = int(\n",
    "        mini_header[mini_header.index('titles.')-1].replace(',', ''))\n",
    "    return num_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soup(url):\n",
    "    response_text = requests.get(url).text\n",
    "    soup = BeautifulSoup(response_text, 'html5lib')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soups(urls):\n",
    "    soups = []\n",
    "    for url in urls:\n",
    "        response_text = requests.get(url).text\n",
    "        soup = BeautifulSoup(response_text, 'html5lib')\n",
    "        soups.append(soup)\n",
    "    return soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I was missing the 's' in title_urls! Be careful about variable names (keep them short and simple)\n",
    "def get_title_urls(soups):\n",
    "    titles_urls = []\n",
    "    for soup in soups:\n",
    "        title_spans = soup.find(\n",
    "            'div', class_='lister-list').find_all('span', class_='lister-item-header')\n",
    "        for element in title_spans:\n",
    "            titles_urls.append(element.find('a').get('href'))\n",
    "    return titles_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1361"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/title/tt12478494/'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/title/tt12280576/'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if my functions work to pull all Japanese animated film urls\n",
    "\n",
    "japan_search_urls = get_search_urls(japan_base_url, japan_next_url)\n",
    "japan_search_soups = create_soups(japan_search_urls)\n",
    "japan_title_urls = get_title_urls(japan_search_soups)\n",
    "len(japan_title_urls)\n",
    "japan_title_urls[9]\n",
    "japan_title_urls[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1485"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/title/tt12203840/'"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/title/tt1620981/'"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if my functions work to pull all American animated film urls\n",
    "\n",
    "american_search_urls = get_search_urls(american_base_url, american_next_url)\n",
    "american_search_soups = create_soups(american_search_urls)\n",
    "american_title_urls = get_title_urls(american_search_soups)\n",
    "len(american_title_urls)\n",
    "american_title_urls[25]\n",
    "american_title_urls[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_name_url = 'https://www.imdb.com/title/tt5311514/'\n",
    "toy_story_2_url = 'https://www.imdb.com/title/tt0120363/'\n",
    "toy_story_3_url = 'https://www.imdb.com/title/tt0435761/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(soup):\n",
    "    if soup.find('h1'):\n",
    "        raw_text = soup.find('h1').text.strip()\n",
    "        return clean_title(raw_text)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_runtime(soup):\n",
    "    if soup.find('time'):\n",
    "        raw_runtime = soup.find('time').text.strip()\n",
    "        return runtime_to_minutes(raw_runtime)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mpaa_rating(soup):\n",
    "    ratings = ['G', 'PG', 'PG-13', 'R', 'TV-PG', 'TV-MA']\n",
    "    if soup.find('div', class_='subtext'):\n",
    "        rating = soup.find('div', class_='subtext').text.strip().split()[0]\n",
    "        if rating in ratings:\n",
    "            return rating\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_rating(soup):\n",
    "    if soup.find('span', itemprop='ratingValue'):\n",
    "        return float(soup.find('span', itemprop='ratingValue').text)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(string):\n",
    "    return re.sub('\\\\xa0.+', '', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_budget(soup):\n",
    "    if soup.find(text='Budget:'):\n",
    "        raw_text = soup.find(\n",
    "            text='Budget:').findParent().findParent().text.strip()\n",
    "        budget = clean_budget(raw_text)\n",
    "        if 'JPY' in budget:\n",
    "            return yen_to_int(budget)\n",
    "        return dollars_to_int(budget)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_budget(string):\n",
    "    string = string.replace('Budget:', '')\n",
    "    string = remove_commas(string)\n",
    "    return re.sub('\\\\n.+', '', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_rating_count(soup):\n",
    "    if soup.find(itemprop='ratingCount'):\n",
    "        raw_text = soup.find(itemprop='ratingCount').text\n",
    "        return int(remove_commas(raw_text))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_commas(string):\n",
    "    return string.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genres(soup):\n",
    "    if soup.find(text='Genres:'):\n",
    "        raw_text = soup.find(\n",
    "            text='Genres:').findParent().findParent().text.strip()\n",
    "        return clean_genres(raw_text)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_genres(string):\n",
    "    string = string.replace('Genres:', '')\n",
    "    string = re.sub('\\\\n ', '', string)\n",
    "    return re.sub('\\\\xa0\\|', ', ', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oscar_wins(soup):\n",
    "    if soup.find('span', class_='awards-blurb'):\n",
    "        if 'Won' in soup.find('span', class_='awards-blurb').text:\n",
    "            raw_text = soup.find('span', class_='awards-blurb').text.strip()\n",
    "            for s in raw_text.split():\n",
    "                if s.isdigit():\n",
    "                    return int(s)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Another', '60', 'wins', '&', '95', 'nominations.']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_story_3_soup.find(\n",
    "    'span', class_='awards-blurb').findNextSibling().text.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_oscar_wins(soup):\n",
    "    if soup.find('span', class_='awards-blurb'):\n",
    "        if 'Oscar' in soup.find('span', class_='awards-blurb').text:\n",
    "            if soup.find('span', class_='awards-blurb').findNextSibling():\n",
    "                raw_text = soup.find(\n",
    "                    'span', class_='awards-blurb').findNextSibling().text.strip()\n",
    "                if 'win' in raw_text:\n",
    "                    for s in raw_text.split():\n",
    "                        if s.isdigit():\n",
    "                            return int(s)                                \n",
    "            return None\n",
    "        else:\n",
    "            raw_text = soup.find('span', class_='awards-blurb').text.strip()\n",
    "            if 'win' in raw_text:\n",
    "                for s in raw_text.split():\n",
    "                    if s.isdigit():\n",
    "                        return int(s) \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metascore(soup):\n",
    "    if soup.find('div', class_='metacriticScore'):\n",
    "        return int(soup.find('div', class_='metacriticScore').text.strip())\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_usa_release_date(soup):\n",
    "    if soup.find(title='See more release dates'):\n",
    "        raw_text = soup.find(\n",
    "            title='See more release dates').text.strip().replace(' (USA)', '')\n",
    "        return to_datetime(raw_text)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"/calendar/?region=jp\">Japan\n",
      "</a>\n"
     ]
    }
   ],
   "source": [
    "for element in spirited_away_release_soup.find_all('a'):\n",
    "    if 'Japan' in element.text:\n",
    "        print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20 July 2001'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spirited_away_release_soup.find(href='/calendar/?region=jp').findNext().text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_name_release_url = 'https://www.imdb.com/title/tt5311514/releaseinfo'\n",
    "your_name_release_soup = create_soup(your_name_release_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'26 August 2016'"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "your_name_release_soup.find(href='/calendar/?region=jp').findNext().text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_japan_release_date(soup):\n",
    "    if soup.find(href='/calendar/?region=jp'):\n",
    "        raw_text = soup.find(href='/calendar/?region=jp').findNext().text\n",
    "        return to_datetime(raw_text)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'26 August 2016'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_japan_release_date(your_name_release_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20 July 2001'"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_japan_release_date(spirited_away_release_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18 June 2010'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_usa_release_date(toy_story_3_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country(soup):\n",
    "    for element in soup.find_all('h4'):\n",
    "        if 'Country:' in element:\n",
    "            return element.findNext().text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_gross(soup):\n",
    "    for element in soup.find_all('h4'):\n",
    "        if 'Cumulative Worldwide Gross:' in element:\n",
    "            raw_text = element.findParent().text.strip()\n",
    "            raw_text = raw_text.replace('Cumulative Worldwide Gross: ', '')\n",
    "            raw_text = remove_commas(raw_text)\n",
    "            return dollars_to_int(raw_text)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtime_to_minutes(raw_runtime):\n",
    "    raw_runtime = raw_runtime.replace('h', '').replace('min', '')\n",
    "    runtime = raw_runtime.split()\n",
    "    minutes = int(runtime[0])*60 + int(runtime[1])\n",
    "    return minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_datetime(datestring):\n",
    "    return dateutil.parser.parse(datestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dollars_to_int(dollars_string):\n",
    "    dollars_string = dollars_string.replace('$', '')\n",
    "    return int(dollars_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yen_to_int(yen_string):\n",
    "    yen_conversion = 106.9\n",
    "    yen_string = yen_string.replace('JPY', '')\n",
    "    return round(int(yen_string) / yen_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3461179"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yen_to_int('JPY370000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998-03-06 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(to_datetime('March 6, 1998'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime_to_minutes('2h 5min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_dict(link):\n",
    "    base_url = 'https://www.imdb.com'\n",
    "    url = base_url + link\n",
    "    soup = create_soup(url)\n",
    "\n",
    "    headers = ['title', 'country', 'runtime_minutes', 'budget', 'global_gross',\n",
    "               'mpaa_rating', 'japan_release_date', 'usa_release_date', 'genres',\n",
    "               'imdb_user_rating', 'imdb_user_rating_count', 'oscar_wins',\n",
    "               'non_oscar_wins']\n",
    "\n",
    "    title = get_title(soup)\n",
    "    country = get_country(soup)\n",
    "    runtime = get_runtime(soup)\n",
    "    budget = get_budget(soup)\n",
    "    global_gross = get_global_gross(soup)\n",
    "    mpaa_rating = get_mpaa_rating(soup)\n",
    "\n",
    "    if country == 'Japan':\n",
    "        release_info_url = url + 'releaseinfo'\n",
    "        release_info_soup = create_soup(release_info_url)\n",
    "        japan_release_date = get_japan_release_date(release_info_soup)\n",
    "        usa_release_date = None\n",
    "    else:\n",
    "        usa_release_date = get_usa_release_date(soup)\n",
    "        japan_release_date = None\n",
    "\n",
    "    genres = get_genres(soup)\n",
    "    imdb_user_rating = get_user_rating(soup)\n",
    "    imdb_user_rating_count = get_user_rating_count(soup)\n",
    "    oscar_wins = get_oscar_wins(soup)\n",
    "    non_oscar_wins = get_non_oscar_wins(soup)\n",
    "\n",
    "    movie_dict = dict(\n",
    "        zip(headers, [title, country, runtime, budget, global_gross,\n",
    "                      mpaa_rating, japan_release_date,\n",
    "                      usa_release_date, genres, imdb_user_rating,\n",
    "                      imdb_user_rating_count, oscar_wins, non_oscar_wins]))\n",
    "\n",
    "    return movie_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Spirited Away',\n",
       " 'country': 'Japan',\n",
       " 'runtime_minutes': 125,\n",
       " 'budget': 19000000,\n",
       " 'global_gross': 350657645,\n",
       " 'mpaa_rating': 'PG',\n",
       " 'japan_release_date': datetime.datetime(2001, 7, 20, 0, 0),\n",
       " 'usa_release_date': None,\n",
       " 'genres': 'Animation, Adventure, Family, Fantasy, Mystery',\n",
       " 'imdb_user_rating': 8.6,\n",
       " 'imdb_user_rating_count': 619086,\n",
       " 'oscar_wins': 1,\n",
       " 'non_oscar_wins': 57}"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_movie_dict('/title/tt0245429/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Your Name.',\n",
       " 'country': 'Japan',\n",
       " 'runtime_minutes': 106,\n",
       " 'budget': 3461179,\n",
       " 'global_gross': 358922706,\n",
       " 'mpaa_rating': 'PG',\n",
       " 'japan_release_date': datetime.datetime(2016, 8, 26, 0, 0),\n",
       " 'usa_release_date': None,\n",
       " 'genres': 'Animation, Drama, Fantasy, Romance',\n",
       " 'imdb_user_rating': 8.4,\n",
       " 'imdb_user_rating_count': 173534,\n",
       " 'oscar_wins': None,\n",
       " 'non_oscar_wins': 15}"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_movie_dict('/title/tt5311514/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Gekijoban G No Reconguista II: Bellri Gekishin',\n",
       " 'country': 'Japan',\n",
       " 'runtime_minutes': 95,\n",
       " 'budget': None,\n",
       " 'global_gross': None,\n",
       " 'mpaa_rating': None,\n",
       " 'japan_release_date': datetime.datetime(2020, 2, 21, 0, 0),\n",
       " 'usa_release_date': None,\n",
       " 'genres': 'Animation',\n",
       " 'imdb_user_rating': None,\n",
       " 'imdb_user_rating_count': None,\n",
       " 'oscar_wins': None,\n",
       " 'non_oscar_wins': None}"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_movie_dict('/title/tt11433900/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Her Blue Sky',\n",
       " 'country': 'Japan',\n",
       " 'runtime_minutes': 106,\n",
       " 'budget': None,\n",
       " 'global_gross': 4736031,\n",
       " 'mpaa_rating': None,\n",
       " 'japan_release_date': datetime.datetime(2019, 10, 11, 0, 0),\n",
       " 'usa_release_date': None,\n",
       " 'genres': 'Animation, Drama, Family, Fantasy, Music, Romance',\n",
       " 'imdb_user_rating': 6.7,\n",
       " 'imdb_user_rating_count': 206,\n",
       " 'oscar_wins': None,\n",
       " 'non_oscar_wins': None}"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_movie_dict('/title/tt10981202/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
