{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project 2 to-dos:**\n",
    "1. Write functions to pull title urls - **DONE**\n",
    "2. Test functions on American/Japanese animated movie search (does it pull all the necessary movie imdb URLs)? - **DONE**\n",
    "3. Read existing literature on box office revenue drivers\n",
    "4. Create a list of necessary features\n",
    "5. Create functions to scrape all the necessary data from each URL\n",
    "6. Put all data into dataframe\n",
    "7. Train models\n",
    "8. Cross-validate models \n",
    "9. Test models\n",
    "10. Explain/visualize results\n",
    "11. Create PPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project 2 Steps:**    \n",
    "1. Literature review\n",
    "2. Web scraping \n",
    "3. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project 2 Questions:**\n",
    "1. What to do about animated films made in both Japan/US? Just take them out of the dataset? Or put them in both the Japan/US regression? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline\n",
    "sns.set(color_codes=True)\n",
    "plt.style.use('seaborn-colorblind')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.precision', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search: https://www.imdb.com/search/title/  \n",
    "Title type: Feature film  \n",
    "Release date: up to July 1, 2020\n",
    "Genres: Animation  \n",
    "Countries: Japan; United States (the countries need to be searched separately)  \n",
    "Display options: Detailed, 100 per page    \n",
    "Adult titles: Exclude  \n",
    "Sorted by: Release date descending  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search: https://pro.imdb.com/find?q=&showRVCWidget=true&ref_=hm_nv_search#keyspace=TITLE&sort=ranking  \n",
    "Type: Movie  \n",
    "Status: Released  \n",
    "Country: United States, Japan  \n",
    "**Note to self:** I can use beautifulsoup to find the individual links for each movie (from a search page) and then do a request for each of those individual links  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "japan_base_url = 'https://www.imdb.com/search/title/?title_type=feature&release_date=,' \\\n",
    "           '2020-07-01&genres=animation&countries=jp&sort=release_date,desc&count=' \\\n",
    "           '100&view=simple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_base_url = 'https://www.imdb.com/search/title/?title_type=feature&release_date=,' \\\n",
    "                    '2020-07-01&genres=animation&countries=us&sort=release_date,desc&count=' \\\n",
    "                    '100&view=simple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "japan_next_url = 'https://www.imdb.com/search/title/?title_type=feature&release_date=,' \\\n",
    "                '2020-07-01&genres=animation&countries=jp&view=simple&sort=release_date,desc&count=' \\\n",
    "                '100&start=101&ref_=adv_nxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_next_url = 'https://www.imdb.com/search/title/?title_type=feature&release_date=,' \\\n",
    "                    '2020-07-01&genres=animation&countries=us&view=simple&sort=release_date,' \\\n",
    "                    'desc&count=100&start=101&ref_=adv_nxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_urls(base_url, next_url):\n",
    "    search_urls = [base_url, next_url]\n",
    "    num_titles = get_num_titles(base_url)\n",
    "\n",
    "    for i in range(num_titles//100-1):\n",
    "        search_urls.append(\n",
    "            next_url.replace('101', str(201+100*i)))\n",
    "    return search_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_titles(base_url):\n",
    "    soup = create_soup(base_url)\n",
    "    mini_header = soup.find('div', class_='desc').findNext().text.split()\n",
    "    num_titles = int(\n",
    "        mini_header[mini_header.index('titles.')-1].replace(',', ''))\n",
    "    return num_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soup(url):\n",
    "    response_text = requests.get(url).text\n",
    "    soup = BeautifulSoup(response_text, 'html5lib')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soups(urls):\n",
    "    soups = []\n",
    "    for url in urls:\n",
    "        response_text = requests.get(url).text\n",
    "        soup = BeautifulSoup(response_text, 'html5lib')\n",
    "        soups.append(soup)\n",
    "    return soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I was missing the 's' in title_urls! Be careful about variable names (keep them short and simple)\n",
    "def get_title_urls(soups):\n",
    "    titles_urls = []\n",
    "    for soup in soups:\n",
    "        title_spans = soup.find(\n",
    "            'div', class_='lister-list').find_all('span', class_='lister-item-header')\n",
    "        for element in title_spans:\n",
    "            titles_urls.append(element.find('a').get('href'))\n",
    "    return titles_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1361"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/title/tt12478494/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/title/tt12280576/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if my functions work to pull all Japanese animated film urls\n",
    "\n",
    "japan_search_urls = get_search_urls(japan_base_url, japan_next_url)\n",
    "japan_search_soups = create_soups(japan_search_urls)\n",
    "japan_title_urls = get_title_urls(japan_search_soups)\n",
    "len(japan_title_urls)\n",
    "japan_title_urls[9]\n",
    "japan_title_urls[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1484"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/title/tt12203840/'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/title/tt1620981/'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if my functions work to pull all American animated film urls\n",
    "\n",
    "american_search_urls = get_search_urls(american_base_url, american_next_url)\n",
    "american_search_soups = create_soups(american_search_urls)\n",
    "american_title_urls = get_title_urls(american_search_soups)\n",
    "len(american_title_urls)\n",
    "american_title_urls[25]\n",
    "american_title_urls[100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
